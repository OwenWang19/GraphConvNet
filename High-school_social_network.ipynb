{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f0919b",
   "metadata": {},
   "source": [
    "# High-school Social Network\n",
    "\n",
    "We will now use a high-school contact network for a node classification task: predict each student’s gender (M/F). - Categorical inputs: class and level (gender is the target and is not used as input). - Structural scalars per node: degree, number of triangles, local clustering coefficient, betweenness, and closeness centrality. Each scalar feature is min–max normalized across nodes. - Model: project to 10‑d, apply three GCN layers with ReLU to get x1, x2, x3 (each 10‑d), then concatenate to a 30‑d vector and use a Linear head to 2 logits. Use CrossEntropyLoss. - Training: use a 75%/25% train/test split of nodes, but keep the full graph for message passing. Compute the loss on the training nodes only.\n",
    "\n",
    "## Exercise 5 \n",
    "Load the node and edge CSVs, build a NetworkX graph G with attributes, and remove nodes with gender == “Unknown”. Files are assumed to be in data/nodes_full.csv and data/edges_full.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919d2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "nodes_df = pd.read_csv(\"data/nodes_full.csv\")\n",
    "edges_df = pd.read_csv(\"data/edges_full.csv\")\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in nodes_df.iterrows():\n",
    "  nid = int(row[\"ID\"])  # canonical numeric id\n",
    "  lvl = row.get(\"level\")\n",
    "  lvl = None if pd.isna(lvl) else int(lvl)\n",
    "  G.add_node(nid, Id=nid, **{\"class\": row.get(\"class\"), \"gender\": row.get(\"gender\"), \"level\": lvl})\n",
    "\n",
    "for _, row in edges_df.iterrows():\n",
    "  u = int(row[\"ID1\"]) ; v = int(row[\"ID2\"]) ; w = int(row.get(\"weight\", 1))\n",
    "  G.add_edge(u, v, weight=w)\n",
    "\n",
    "# Remove nodes with unknown gender; keep only M/F\n",
    "unknown = [n for n, d in G.nodes(data=True) if str(d.get(\"gender\")) == \"Unknown\"]\n",
    "G.remove_nodes_from(unknown)\n",
    "G = G.subgraph([n for n, d in G.nodes(data=True) if str(d.get('gender')) in ('M','F')]).copy()\n",
    "\n",
    "print(f\"High-school graph -> Nodes: {G.number_of_nodes()}, Edges: {G.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a81050",
   "metadata": {},
   "source": [
    "## Exercise 6 \n",
    "Engineer features (categoricals and structural scalars), construct the corresponding tensors, and create 75%/25% train/test node masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc733bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "# Categorical indices for class and level (level has 0 as the missing index)\n",
    "classes = sorted({str(G.nodes[n].get('class')) for n in G.nodes()})\n",
    "class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "levels = [G.nodes[n].get('level') for n in G.nodes()]\n",
    "unique_levels = sorted({int(l) for l in levels if l is not None})\n",
    "level_to_idx = {l: i+1 for i, l in enumerate(unique_levels)}\n",
    "\n",
    "nodes = sorted(G.nodes())\n",
    "idx_of = {n: i for i, n in enumerate(nodes)}\n",
    "N = len(nodes)\n",
    "\n",
    "class_idx = torch.tensor([class_to_idx[str(G.nodes[n].get('class'))] for n in nodes], dtype=torch.long)\n",
    "level_idx = torch.tensor([level_to_idx.get(G.nodes[n].get('level'), 0) for n in nodes], dtype=torch.long)\n",
    "\n",
    "# Structural scalars\n",
    "deg = dict(G.degree())\n",
    "tri = nx.triangles(G)\n",
    "clu = nx.clustering(G)\n",
    "bet = nx.betweenness_centrality(G, normalized=True)\n",
    "clo = nx.closeness_centrality(G)\n",
    "\n",
    "scalars = torch.stack([\n",
    "  torch.tensor([deg[n] for n in nodes], dtype=torch.float32),\n",
    "  torch.tensor([tri[n] for n in nodes], dtype=torch.float32),\n",
    "  torch.tensor([clu[n] for n in nodes], dtype=torch.float32),\n",
    "  torch.tensor([bet[n] for n in nodes], dtype=torch.float32),\n",
    "  torch.tensor([clo[n] for n in nodes], dtype=torch.float32),\n",
    "], dim=1)\n",
    "\n",
    "# Min–max normalize per column\n",
    "mins = scalars.min(dim=0).values\n",
    "maxs = scalars.max(dim=0).values\n",
    "scalars = (scalars - mins) / (maxs - mins + 1e-12)\n",
    "\n",
    "# Labels F=0, M=1\n",
    "gender_to_idx = {'F': 0, 'M': 1}\n",
    "y = torch.tensor([gender_to_idx[str(G.nodes[n].get('gender'))] for n in nodes], dtype=torch.long)\n",
    "\n",
    "# Edge tensors\n",
    "import torch\n",
    "edges = torch.tensor([(idx_of[u], idx_of[v]) for u, v in G.edges()], dtype=torch.long).t().contiguous()\n",
    "edge_w = torch.tensor([G[u][v].get('weight', 1) for u, v in G.edges()], dtype=torch.float32)\n",
    "edge_index, edge_w = to_undirected(edges, edge_attr=edge_w, num_nodes=N)\n",
    "\n",
    "# Train/test masks (75%/25%)\n",
    "perm = torch.randperm(N)\n",
    "n_train = int(0.75 * N)\n",
    "train_idx = perm[:n_train]\n",
    "test_idx = perm[n_train:]\n",
    "train_mask = torch.zeros(N, dtype=torch.bool); train_mask[train_idx] = True\n",
    "test_mask = torch.zeros(N, dtype=torch.bool); test_mask[test_idx] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16730e88",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "Define and train the 3‑hop GCN (with dropout) to predict gender using CrossEntropyLoss on the training nodes only. Report training loss and training accuracy periodically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59761035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class HSNet(nn.Module):\n",
    "  def __init__(self, num_classes, num_levels, scalar_dim=5, hidden_dim=10, dropout=0.1):\n",
    "    super().__init__()\n",
    "    self.class_emb = nn.Embedding(num_classes, hidden_dim)\n",
    "    self.level_emb = nn.Embedding(num_levels + 1, hidden_dim)  # 0 for missing\n",
    "    self.in_lin = nn.Linear(hidden_dim*2 + scalar_dim, hidden_dim)\n",
    "    self.conv1 = GCNConv(hidden_dim, hidden_dim, add_self_loops=True)\n",
    "    self.conv2 = GCNConv(hidden_dim, hidden_dim, add_self_loops=True)\n",
    "    self.conv3 = GCNConv(hidden_dim, hidden_dim, add_self_loops=True)\n",
    "    self.drop = nn.Dropout(p=dropout)\n",
    "    self.head = nn.Linear(hidden_dim*3, 2)\n",
    "  def forward(self, class_idx, level_idx, scalars, edge_index, edge_weight=None):\n",
    "    x = torch.cat([self.class_emb(class_idx), self.level_emb(level_idx), scalars], dim=1)\n",
    "    x = F.relu(self.in_lin(x)); x = self.drop(x)\n",
    "    x1 = F.relu(self.conv1(x, edge_index, edge_weight=edge_weight)); x1 = self.drop(x1)\n",
    "    x2 = F.relu(self.conv2(x1, edge_index, edge_weight=edge_weight)); x2 = self.drop(x2)\n",
    "    x3 = F.relu(self.conv3(x2, edge_index, edge_weight=edge_weight)); x3 = self.drop(x3)\n",
    "    z = torch.cat([x1, x2, x3], dim=1)\n",
    "    return self.head(z)\n",
    "\n",
    "model = HSNet(num_classes=len(class_to_idx), num_levels=len(unique_levels), scalar_dim=scalars.size(1), hidden_dim=10, dropout=0.3)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(20000):\n",
    "  model.train(); opt.zero_grad()\n",
    "  logits = model(class_idx, level_idx, scalars, edge_index, edge_weight=edge_w)\n",
    "  loss = crit(logits[train_mask], y[train_mask])\n",
    "  loss.backward(); opt.step()\n",
    "  if epoch % 1000 == 0:\n",
    "    with torch.no_grad():\n",
    "      acc_tr = (logits[train_mask].argmax(dim=1) == y[train_mask]).float().mean().item()\n",
    "    print(f\"epoch {epoch:4d} | train loss {loss.item():.4f} | train acc {acc_tr:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  logits = model(class_idx, level_idx, scalars, edge_index, edge_weight=edge_w)\n",
    "  acc_tr = (logits[train_mask].argmax(dim=1) == y[train_mask]).float().mean().item()\n",
    "print(f\"Final training accuracy (train 75%): {acc_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a5c8e8",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "Produce diagnostics: parameter counts, tensor shapes (key tensors), and evaluate on the held‑out 25% test nodes (accuracy and confusion matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def count_parameters(m):\n",
    "  total = 0; per_module = {}\n",
    "  print(\"Parameters by tensor:\")\n",
    "  for name, p in m.named_parameters():\n",
    "    n = p.numel(); total += n; mod = name.split('.')[0]\n",
    "    per_module[mod] = per_module.get(mod, 0) + n\n",
    "    print(f\"  {name:35s} {tuple(p.shape)} -> {n}\")\n",
    "  print(\"\\nParameters by top-level module:\")\n",
    "  for mod, cnt in sorted(per_module.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {mod:15s} -> {cnt}\")\n",
    "  print(f\"Total parameters: {total}\")\n",
    "\n",
    "count_parameters(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "  emb_c = model.class_emb(class_idx)\n",
    "  emb_l = model.level_emb(level_idx)\n",
    "  xcat  = torch.cat([emb_c, emb_l, scalars], 1)\n",
    "  x0    = F.relu(model.in_lin(xcat))\n",
    "  x1    = F.relu(model.conv1(x0, edge_index, edge_weight=edge_w))\n",
    "  x2    = F.relu(model.conv2(x1, edge_index, edge_weight=edge_w))\n",
    "  x3    = F.relu(model.conv3(x2, edge_index, edge_weight=edge_w))\n",
    "  z     = torch.cat([x1, x2, x3], 1)\n",
    "  logits = model.head(z)\n",
    "\n",
    "print(\"\\nTensor shapes:\")\n",
    "print(\"  class_emb:\", tuple(emb_c.shape))\n",
    "print(\"  level_emb:\", tuple(emb_l.shape))\n",
    "print(\"  concat [class_emb, level_emb, scalars]:\", tuple(xcat.shape))\n",
    "print(\"  after in_lin+ReLU:\", tuple(x0.shape))\n",
    "print(\"  x1 (GCN1+ReLU):\", tuple(x1.shape))\n",
    "print(\"  x2 (GCN2+ReLU):\", tuple(x2.shape))\n",
    "print(\"  x3 (GCN3+ReLU):\", tuple(x3.shape))\n",
    "print(\"  z = concat[x1,x2,x3]:\", tuple(z.shape))\n",
    "print(\"  logits:\", tuple(logits.shape))\n",
    "\n",
    "with torch.no_grad():\n",
    "  pred = logits.argmax(1)\n",
    "  test_acc = (pred[test_mask] == y[test_mask]).float().mean().item()\n",
    "\n",
    "cm = np.zeros((2,2), dtype=int)\n",
    "for t, p in zip(y[test_mask].tolist(), pred[test_mask].tolist()):\n",
    "  cm[t][p] += 1\n",
    "\n",
    "print(f\"\\nTest accuracy (25%): {test_acc:.4f}\")\n",
    "print(\"Confusion matrix (rows=true, cols=pred) on test set:\")\n",
    "print(\"          Pred F    Pred M\")\n",
    "print(f\"True F   {cm[0,0]:7d}   {cm[0,1]:7d}\")\n",
    "print(f\"True M   {cm[1,0]:7d}   {cm[1,1]:7d}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
